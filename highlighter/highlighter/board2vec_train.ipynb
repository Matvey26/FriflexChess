{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужные импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import chess\n",
    "import pandas as pd\n",
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала энкодер досок.\n",
    "\n",
    "Кодирует доску в виде 15-канального изображения. Происходит что-то типо OneHotEncoder на уровне фигур и цветов. Например один из каналов выглядит так:\n",
    "\n",
    "```\n",
    "0 0 0 0 0 0 0 0\n",
    "1 1 1 1 1 1 1 1\n",
    "0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0\n",
    "0 0 0 0 0 0 0 0\n",
    "```\n",
    "\n",
    "Это слой с чёрными пешками.\n",
    "\n",
    "Также кодируется информация о взятии на проходе, рокировке и превращении пешки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Literal, Union, List, Tuple\n",
    "\n",
    "\n",
    "class MatrixEncoder:\n",
    "    def encode(self, board: chess.Board) -> np.ndarray:\n",
    "        # 12 каналов для фигур\n",
    "        board_state = np.zeros((15, 8, 8), dtype=np.float32)\n",
    "\n",
    "        # 1. Кодируем состояние доски\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece is not None:\n",
    "                # Определяем канал:\n",
    "                # 0-5: пешка, конь, слон, ладья, ферзь, король\n",
    "                channel = piece.piece_type - 1\n",
    "                if piece.color == chess.BLACK:\n",
    "                    channel += 6\n",
    "                row = square // 8\n",
    "                col = square % 8\n",
    "                board_state[channel, row, col] = 1.0\n",
    "\n",
    "        # 2. Дополнительные признаки\n",
    "        if board.has_kingside_castling_rights(chess.WHITE):\n",
    "            board_state[12][7, 4] = 1.0  # Король белых на e1\n",
    "        if board.has_queenside_castling_rights(chess.WHITE):\n",
    "            board_state[12][7, 4] = 1.0  # Король белых на e1\n",
    "        if board.has_kingside_castling_rights(chess.BLACK):\n",
    "            board_state[12][7, 0] = -1.0  # Король чёрных на e8\n",
    "        if board.has_queenside_castling_rights(chess.BLACK):\n",
    "            board_state[12][7, 0] = -1.0  # Король чёрных на e8\n",
    "\n",
    "        if board.ep_square is not None:\n",
    "            ep_row = board.ep_square // 8\n",
    "            ep_col = board.ep_square % 8\n",
    "            board_state[13][ep_row, ep_col] = 1.0\n",
    "\n",
    "        if board.peek() and board.peek().promotion is None:\n",
    "            last_move = board.peek()\n",
    "            if abs(last_move.from_square - last_move.to_square) == 16:  # Ход на две клетки\n",
    "                double_move_row = last_move.to_square // 8\n",
    "                double_move_col = last_move.to_square % 8\n",
    "                board_state[14][double_move_row, double_move_col] = 1.0\n",
    "\n",
    "        return board_state\n",
    "\n",
    "    def get_encoded_shape(self):\n",
    "        return (15, 8, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь архитектура модели\n",
    "\n",
    "Residual блоки пока особо смысла не имеют, но можно попробовать обучить более глубокую модель.\n",
    "\n",
    "Также было было предложено сравнить с обычным перцептроном"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Board2Vec(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Входной блок с 15 каналов (6 фигур × 2 цвета + информация про рокировку, взятие на проходе и promotion)\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(15, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Резидуальные блоки\n",
    "        self.block1 = ResidualBlock(hidden_dim)\n",
    "        self.block2 = ResidualBlock(hidden_dim)\n",
    "\n",
    "        # Глобальный пуллинг и финальные слои\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, boards: torch.Tensor):\n",
    "        # boards: (batch_size, 15, 8, 8)\n",
    "        x = self.initial(boards)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Конкатенация с дополнительными признаками\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовка датасета происходит в другом [ноутбуке](prepare_dataset.ipynb)\n",
    "\n",
    "Здесь происходит загрузка датасета. В функции getitem выбирается случайный файл и случайная позиция в нём (таргет). Далее выбирается случайная позиция из окна контекста (контекст). Наконец набирается некоторое количество негативных примеров - либо вне окна контекста, либо из предзаготовленного пула"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import lru_cache\n",
    "from time import time\n",
    "\n",
    "# Настройка логгера\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s [%(levelname)s] %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('chess_dataset.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.disabled = True\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, data_dir, context_size=5, negatives_count=10, min_game_length=11):\n",
    "        start_time = time()\n",
    "        logger.info(\"Инициализация ChessDataset с data_dir=%s, context_size=%d, negatives_count=%d, min_game_length=%d\",\n",
    "                    data_dir, context_size, negatives_count, min_game_length)\n",
    "        \n",
    "        self.data_dir = data_dir\n",
    "        self.context_size = context_size\n",
    "        self.negatives_count = negatives_count\n",
    "        self.min_game_length = max(min_game_length, 2 * context_size + 1)\n",
    "        \n",
    "        # Собираем только подходящие игры\n",
    "        self.game_files = [f for f in os.listdir(data_dir) if f.endswith('.npy')]\n",
    "        logger.info(\"Найдено %d .npy файлов\", len(self.game_files))\n",
    "        \n",
    "        self.valid_game_files = []\n",
    "        for game_file in self.game_files:\n",
    "            try:\n",
    "                game_path = os.path.join(self.data_dir, game_file)\n",
    "                game_length = len(np.load(game_path, mmap_mode='r'))\n",
    "                if game_length >= self.min_game_length:\n",
    "                    self.valid_game_files.append(game_file)\n",
    "                else:\n",
    "                    logger.warning(\"Игра %s слишком короткая (длина=%d, требуется=%d), пропущена\",\n",
    "                                  game_file, game_length, self.min_game_length)\n",
    "            except Exception as e:\n",
    "                logger.error(\"Ошибка при проверке файла %s: %s\", game_file, str(e))\n",
    "        \n",
    "        if not self.valid_game_files:\n",
    "            logger.error(\"Нет игр, удовлетворяющих минимальной длине!\")\n",
    "            raise ValueError(\"Нет игр, удовлетворяющих минимальной длине!\")\n",
    "        \n",
    "        logger.info(\"Найдено %d валидных игр\", len(self.valid_game_files))\n",
    "        \n",
    "        # Кэшируем загрузку игр\n",
    "        self._load_game = lru_cache(maxsize=10)(self._load_game)\n",
    "\n",
    "        # Создаем пул игр для добора негативных примеров\n",
    "        self.pool_size = min(20, len(self.valid_game_files))\n",
    "        self.pool_files = random.sample(self.valid_game_files, self.pool_size)\n",
    "        self.pool_data = [self._load_game(f) for f in self.pool_files]\n",
    "        logger.info(\"Создан пул из %d игр для негативных примеров\", self.pool_size)\n",
    "        \n",
    "        logger.info(\"Инициализация завершена за %.2f секунд\", time() - start_time)\n",
    "    \n",
    "    def _load_game(self, game_file):\n",
    "        \"\"\"Загружает игру с помощью mmap\"\"\"\n",
    "        start_time = time()\n",
    "        logger.debug(\"Загрузка игры %s\", game_file)\n",
    "        try:\n",
    "            game_data = np.load(os.path.join(self.data_dir, game_file), mmap_mode='r')\n",
    "            logger.debug(\"Игра %s загружена за %.2f секунд, длина=%d\",\n",
    "                        game_file, time() - start_time, len(game_data))\n",
    "            return game_data\n",
    "        except Exception as e:\n",
    "            logger.error(\"Ошибка при загрузке игры %s: %s\", game_file, str(e))\n",
    "            raise\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Примерная оценка количества примеров\"\"\"\n",
    "        length = len(self.valid_game_files) * 50\n",
    "        logger.info(\"Возвращена примерная длина датасета: %d\", length)\n",
    "        return length\n",
    "    \n",
    "    def _get_random_position(self):\n",
    "        \"\"\"Выбирает случайную игру и позицию\"\"\"\n",
    "        start_time = time()\n",
    "        game_file = random.choice(self.valid_game_files)\n",
    "        game_data = self._load_game(game_file)\n",
    "        pos_idx = random.randint(self.context_size, len(game_data) - self.context_size - 1)\n",
    "        logger.debug(\"Выбрана позиция: игра=%s, индекс=%d, время=%.2f секунд\",\n",
    "                    game_file, pos_idx, time() - start_time)\n",
    "        return game_file, pos_idx\n",
    "    \n",
    "    def __getitem__(self, _):\n",
    "        \"\"\"Генерирует пример\"\"\"\n",
    "        start_time = time()\n",
    "        logger.debug(\"Запрошен пример\")\n",
    "        \n",
    "        try:\n",
    "            # Выбор случайной позиции\n",
    "            game_file, pos_idx = self._get_random_position()\n",
    "            game_data = self._load_game(game_file)\n",
    "            \n",
    "            # Таргет\n",
    "            target = game_data[pos_idx]\n",
    "            logger.debug(\"Таргет выбран, форма=%s\", str(target.shape))\n",
    "            \n",
    "            # Контекст\n",
    "            start = max(0, pos_idx - self.context_size)\n",
    "            end = min(len(game_data), pos_idx + self.context_size + 1)\n",
    "            context = game_data[random.randint(start, end - 1)]\n",
    "            logger.debug(\"Контекст выбран, форма=%s\", str(context.shape))\n",
    "            \n",
    "            # Негативные примеры\n",
    "            neg_indices = []\n",
    "            for _ in range(self.negatives_count):\n",
    "                neg_idx = random.randint(0, len(game_data) - 1)\n",
    "                if abs(neg_idx - pos_idx) > self.context_size + 3:\n",
    "                    neg_indices.append(neg_idx)\n",
    "            \n",
    "            # Если не хватает негативных примеров, добираем из пула\n",
    "            if len(neg_indices) < self.negatives_count:\n",
    "                needed = self.negatives_count - len(neg_indices)\n",
    "                logger.debug(\"Не хватает %d негативных примеров, добираем из пула\", needed)\n",
    "                \n",
    "                for _ in range(needed):\n",
    "                    # Выбираем случайную игру из пула\n",
    "                    pool_game_data = random.choice(self.pool_data)\n",
    "                    # Выбираем случайную позицию из этой игры\n",
    "                    neg_idx = random.randint(0, len(pool_game_data) - 1)\n",
    "                    neg_indices.append((pool_game_data, neg_idx))\n",
    "            \n",
    "            # Собираем все негативные примеры\n",
    "            negatives = []\n",
    "            for idx in neg_indices:\n",
    "                if isinstance(idx, tuple):  # пример из пула\n",
    "                    game, i = idx\n",
    "                    negatives.append(game[i])\n",
    "                else:  # пример из текущей игры\n",
    "                    negatives.append(game_data[idx])\n",
    "            \n",
    "            negatives = np.stack(negatives)\n",
    "            logger.debug(\"Негативные примеры выбраны, форма=%s\", str(negatives.shape))\n",
    "            \n",
    "            # Конвертация в тензоры\n",
    "            target = torch.from_numpy(target.copy()).float()\n",
    "            context = torch.from_numpy(context.copy()).float()\n",
    "            negatives = torch.from_numpy(negatives.copy()).float()\n",
    "            \n",
    "            logger.info(\"Пример сгенерирован за %.2f секунд: target_shape=%s, context_shape=%s, negatives_shape=%s\",\n",
    "                       time() - start_time, str(target.shape), str(context.shape), str(negatives.shape))\n",
    "            \n",
    "            return target, context, negatives\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(\"Ошибка при генерации примера: %s\", str(e))\n",
    "            raise\n",
    "    \n",
    "def create_dataloader(data_dir, batch_size=32, num_workers=4, **kwargs):\n",
    "    start_time = time()\n",
    "    logger.info(\"Создание DataLoader с batch_size=%d, num_workers=%d\", batch_size, num_workers)\n",
    "    \n",
    "    try:\n",
    "        dataset = ChessDataset(data_dir, **kwargs)\n",
    "        dataloader = DataLoader(\n",
    "            dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True if num_workers > 0 else False\n",
    "        )\n",
    "        logger.info(\"DataLoader создан за %.2f секунд\", time() - start_time)\n",
    "        return dataloader\n",
    "    except Exception as e:\n",
    "        logger.error(\"Ошибка при создании DataLoader: %s\", str(e))\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(target_embed: torch.Tensor, context_embed: torch.Tensor, negatives_embed: torch.Tensor):\n",
    "    # Положительные примеры: скалярное произведение между target и context\n",
    "    pos_scores = torch.mul(target_embed, context_embed).sum(dim=1)\n",
    "    pos_loss = -torch.nn.functional.logsigmoid(pos_scores)\n",
    "\n",
    "    # Негативные примеры: скалярное произведение между target и negatives\n",
    "    neg_scores = torch.bmm(negatives_embed, target_embed.unsqueeze(2)).squeeze(2)\n",
    "    neg_loss = -torch.nn.functional.logsigmoid(-neg_scores).sum(dim=1)\n",
    "\n",
    "    # Общая потеря: усредняем по батчу\n",
    "    loss = (pos_loss + neg_loss).mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "CONTEXT_SIZE = 6\n",
    "NUM_WORKERS = 0\n",
    "NEGATIVES_COUNT = 5\n",
    "MIN_GAME_LENGTH = 15\n",
    "\n",
    "HIDDEN_DIM = 128\n",
    "OUTPUT_DIM = 64\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "\n",
    "\n",
    "class Board2VecLightning(L.LightningModule):\n",
    "    def __init__(self, hidden_dim, output_dim, num_channel, negatives_cnt):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.negatives_cnt = negatives_cnt\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.num_channel = num_channel\n",
    "        self.board2vec = Board2Vec(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.board2vec(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        target, context, negatives = batch\n",
    "        negatives = negatives.view(-1, self.num_channel, 8, 8)\n",
    "\n",
    "        target_embed = self.forward(target)\n",
    "        context_embed = self.forward(context)\n",
    "        negatives_embed = self.forward(negatives).reshape((-1, self.negatives_cnt, self.output_dim))\n",
    "        loss = criterion(target_embed, context_embed, negatives_embed)\n",
    "\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        target, context, negatives = batch\n",
    "        negatives = negatives.view(-1, self.num_channel, 8, 8)\n",
    "\n",
    "        target_embed = self.forward(target)\n",
    "        context_embed = self.forward(context)\n",
    "        negatives_embed = self.forward(negatives).reshape((-1, self.negatives_cnt, self.output_dim))\n",
    "        loss = criterion(target_embed, context_embed, negatives_embed)\n",
    "\n",
    "        self.log(\"test_loss\", loss)\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        target, context, negatives = batch\n",
    "        negatives = negatives.view(-1, self.num_channel, 8, 8)\n",
    "\n",
    "        target_embed = self.forward(target)\n",
    "        context_embed = self.forward(context)\n",
    "        negatives_embed = self.forward(negatives).reshape((-1, self.negatives_cnt, self.output_dim))\n",
    "        loss = criterion(target_embed, context_embed, negatives_embed)\n",
    "\n",
    "        self.log(\"val_loss\", loss)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=LEARNING_RATE)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = create_dataloader(\n",
    "    'C:/Users/matvey/Documents/chess_data/shit/train',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    negatives_count=NEGATIVES_COUNT,\n",
    "    min_game_length=MIN_GAME_LENGTH\n",
    ")\n",
    "test_loader = create_dataloader(\n",
    "    'C:/Users/matvey/Documents/chess_data/shit/test',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    negatives_count=NEGATIVES_COUNT,\n",
    "    min_game_length=MIN_GAME_LENGTH\n",
    ")\n",
    "val_loader = create_dataloader(\n",
    "    'C:/Users/matvey/Documents/chess_data/shit/val',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    context_size=CONTEXT_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    negatives_count=NEGATIVES_COUNT,\n",
    "    min_game_length=MIN_GAME_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "2025-05-03 15:34:22,498 [INFO] Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "INFO: GPU available: False, used: False\n",
      "2025-05-03 15:34:22,510 [INFO] GPU available: False, used: False\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "2025-05-03 15:34:22,512 [INFO] TPU available: False, using: 0 TPU cores\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "2025-05-03 15:34:22,514 [INFO] HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "INFO: \n",
      "  | Name      | Type      | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | board2vec | Board2Vec | 633 K  | train\n",
      "------------------------------------------------\n",
      "633 K     Trainable params\n",
      "0         Non-trainable params\n",
      "633 K     Total params\n",
      "2.533     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "2025-05-03 15:34:22,520 [INFO] \n",
      "  | Name      | Type      | Params | Mode \n",
      "------------------------------------------------\n",
      "0 | board2vec | Board2Vec | 633 K  | train\n",
      "------------------------------------------------\n",
      "633 K     Trainable params\n",
      "0         Non-trainable params\n",
      "633 K     Total params\n",
      "2.533     Total estimated model params size (MB)\n",
      "23        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d217f9dbc0b4c1392b06383cea89518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n",
      "c:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54dd604136c84922b688c73576c50269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966c69a0140f4dd7bc94a178dd5982c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e8c3f4050f4cc897b9b2b0f97b82d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83481a82bbbe4a809f8bd3e33f3432ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6bcff300b174a768ae8c58c63a0aadb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f30138167a846db864661cb2fe8bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n",
      "2025-05-03 15:59:47,886 [INFO] \n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trainer_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[0;32m    595\u001b[0m     ckpt_path,\n\u001b[0;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    598\u001b[0m )\n\u001b[1;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[1;34m(self, data_fetcher)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[1;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[1;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[1;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[1;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[1;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\core\\module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[1;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[0;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[0;32m   1280\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \n\u001b[0;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\core\\optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[1;34m(self, closure, **kwargs)\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy\u001b[38;5;241m.\u001b[39moptimizer_step(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer, closure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\strategies\\strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[1;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[1;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39moptimizer_step(optimizer, model\u001b[38;5;241m=\u001b[39mmodel, closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[1;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[1;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39mclosure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:485\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    482\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m             )\n\u001b[1;32m--> 485\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\torch\\optim\\optimizer.py:79\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 79\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\torch\\optim\\adam.py:225\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[1;32m--> 225\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\plugins\\precision\\precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[1;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    107\u001b[0m \n\u001b[0;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[1;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[1;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:329\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[1;34m(self, kwargs)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    324\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping the `training_step` by returning None in distributed training is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m It is recommended that you rewrite your training logic to avoid having to skip the step in the first\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m place.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    327\u001b[0m     )\n\u001b[1;32m--> 329\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_result_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_training_step_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_step_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccumulate_grad_batches\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:85\u001b[0m, in \u001b[0;36mClosureResult.from_training_step_output\u001b[1;34m(cls, training_step_output, normalize)\u001b[0m\n\u001b[0;32m     83\u001b[0m     closure_loss \u001b[38;5;241m=\u001b[39m closure_loss \u001b[38;5;241m/\u001b[39m normalize\n\u001b[1;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<string>:5\u001b[0m, in \u001b[0;36m__init__\u001b[1;34m(self, closure_loss, extra)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:54\u001b[0m, in \u001b[0;36mClosureResult.__post_init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__post_init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clone_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\loops\\optimization\\automatic.py:59\u001b[0m, in \u001b[0;36mClosureResult._clone_loss\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m# the loss will get scaled for amp. avoid any modifications to it\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclone()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m Board2VecLightning(\n\u001b[0;32m      2\u001b[0m     hidden_dim\u001b[38;5;241m=\u001b[39mHIDDEN_DIM,\n\u001b[0;32m      3\u001b[0m     output_dim\u001b[38;5;241m=\u001b[39mOUTPUT_DIM,\n\u001b[0;32m      4\u001b[0m     num_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m,\n\u001b[0;32m      5\u001b[0m     negatives_cnt\u001b[38;5;241m=\u001b[39mNEGATIVES_COUNT\n\u001b[0;32m      6\u001b[0m )\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m L\u001b[38;5;241m.\u001b[39mTrainer()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\matvey\\workspace\\FriflexChess\\.venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[0;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[1;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[0;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "model = Board2VecLightning(\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    output_dim=OUTPUT_DIM,\n",
    "    num_channel=15,\n",
    "    negatives_cnt=NEGATIVES_COUNT\n",
    ")\n",
    "trainer = L.Trainer()\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
