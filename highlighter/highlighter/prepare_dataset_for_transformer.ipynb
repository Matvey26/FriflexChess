{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40c618fa-c5cc-4cb4-a911-4a6a01f5fc40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T22:12:59.230281Z",
     "iopub.status.busy": "2025-05-04T22:12:59.226449Z",
     "iopub.status.idle": "2025-05-04T22:12:59.263352Z",
     "shell.execute_reply": "2025-05-04T22:12:59.262376Z",
     "shell.execute_reply.started": "2025-05-04T22:12:59.230171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch\n",
    "import numpy as np\n",
    "from typing import Literal, Union, List, Tuple\n",
    "\n",
    "\n",
    "class MatrixEncoder:\n",
    "    def encode(self, board: chess.Board) -> np.ndarray:\n",
    "        # 12 каналов для фигур\n",
    "        board_state = np.zeros((12, 8, 8), dtype=np.float32)\n",
    "\n",
    "        # 1. Кодируем состояние доски\n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece is not None:\n",
    "                # Определяем канал:\n",
    "                # 0-5: пешка, конь, слон, ладья, ферзь, король\n",
    "                channel = piece.piece_type - 1\n",
    "                if piece.color == chess.BLACK:\n",
    "                    channel += 6\n",
    "                row = square // 8\n",
    "                col = square % 8\n",
    "                board_state[channel, row, col] = 1.0\n",
    "\n",
    "#         # 2. Дополнительные признаки\n",
    "#         if board.has_kingside_castling_rights(chess.WHITE):\n",
    "#             board_state[12][7, 4] = 1.0  # Король белых на e1\n",
    "#         if board.has_queenside_castling_rights(chess.WHITE):\n",
    "#             board_state[12][7, 4] = 1.0  # Король белых на e1\n",
    "#         if board.has_kingside_castling_rights(chess.BLACK):\n",
    "#             board_state[12][7, 0] = -1.0  # Король чёрных на e8\n",
    "#         if board.has_queenside_castling_rights(chess.BLACK):\n",
    "#             board_state[12][7, 0] = -1.0  # Король чёрных на e8\n",
    "\n",
    "#         if board.ep_square is not None:\n",
    "#             ep_row = board.ep_square // 8\n",
    "#             ep_col = board.ep_square % 8\n",
    "#             board_state[13][ep_row, ep_col] = 1.0\n",
    "\n",
    "#         if board.peek() and board.peek().promotion is None:\n",
    "#             last_move = board.peek()\n",
    "#             if abs(last_move.from_square - last_move.to_square) == 16:  # Ход на две клетки\n",
    "#                 double_move_row = last_move.to_square // 8\n",
    "#                 double_move_col = last_move.to_square % 8\n",
    "#                 board_state[14][double_move_row, double_move_col] = 1.0\n",
    "\n",
    "        return board_state\n",
    "\n",
    "    def get_encoded_shape(self):\n",
    "        return (12, 8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd0608c3-a42a-4709-bb51-9651f5b282f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T22:12:59.266088Z",
     "iopub.status.busy": "2025-05-04T22:12:59.264978Z",
     "iopub.status.idle": "2025-05-04T22:12:59.297661Z",
     "shell.execute_reply": "2025-05-04T22:12:59.296805Z",
     "shell.execute_reply.started": "2025-05-04T22:12:59.266040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import chess\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "class MovesToNpyConverter:\n",
    "    def __init__(\n",
    "        self,\n",
    "        csv_path,\n",
    "        encoder,\n",
    "        output_dir,\n",
    "        max_games=None,\n",
    "        min_moves=10,\n",
    "        splits={\"train\": 0.7, \"val\": 0.15, \"test\": 0.15},\n",
    "    ):\n",
    "        self.csv_path = csv_path\n",
    "        self.encoder = encoder\n",
    "        self.output_dir = output_dir\n",
    "        self.max_games = max_games\n",
    "        self.min_moves = min_moves\n",
    "        self.splits = splits\n",
    "        \n",
    "        # Проверяем, что сумма долей равна 1 (с учётом погрешности float)\n",
    "        assert abs(sum(splits.values()) - 1.0) < 1e-6, \"Сумма долей должна быть равна 1\"\n",
    "        \n",
    "        # Создаём поддиректории для train, val и test\n",
    "        self.subdirs = {}\n",
    "        for split_name in splits.keys():\n",
    "            dir_path = os.path.join(output_dir, split_name)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            self.subdirs[split_name] = dir_path\n",
    "            \n",
    "        # Создаём директорию для нового CSV\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    def process_games(self):\n",
    "        # Читаем CSV файл\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        game_count = 0\n",
    "        split_counts = {name: 0 for name in self.splits.keys()}\n",
    "        output_data = []\n",
    "        \n",
    "        total = self.max_games if self.max_games is not None else len(df)\n",
    "        with tqdm(total=total, desc=\"Processing games\") as pbar:\n",
    "            for idx, row in df.iterrows():\n",
    "                if self.max_games is not None and game_count >= self.max_games:\n",
    "                    break\n",
    "                \n",
    "                moves_str = row['moves']\n",
    "                marks = row['marks']\n",
    "                moves = moves_str.split()\n",
    "                \n",
    "                if len(moves) >= self.min_moves:\n",
    "                    board = chess.Board()\n",
    "                    positions = []\n",
    "                    \n",
    "                    try:\n",
    "                        for move in moves:\n",
    "                            chess_move = board.parse_uci(move)\n",
    "                            board.push(chess_move)\n",
    "                            positions.append(self.encoder.encode(board))\n",
    "                            \n",
    "                        # Выбираем, в какую директорию сохранять\n",
    "                        rand_val = random.random()\n",
    "                        cumulative_prob = 0\n",
    "                        for split_name, prob in self.splits.items():\n",
    "                            cumulative_prob += prob\n",
    "                            if rand_val <= cumulative_prob:\n",
    "                                save_dir = self.subdirs[split_name]\n",
    "                                split_counts[split_name] += 1\n",
    "                                break\n",
    "                        \n",
    "                        # Сохраняем всю партию в один .npy файл\n",
    "                        filename = f\"game_{game_count}.npy\"\n",
    "                        rel_path = os.path.join(os.path.basename(save_dir), filename)\n",
    "                        game_array = np.stack(positions)\n",
    "                        np.save(os.path.join(save_dir, filename), game_array)\n",
    "                        \n",
    "                        # Добавляем запись в выходной датасет\n",
    "                        output_data.append({\n",
    "                            'path': rel_path,\n",
    "                            'marks': marks\n",
    "                        })\n",
    "                        \n",
    "                        game_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Ошибка обработки игры {idx}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                pbar.update(1)\n",
    "                if self.max_games is not None:\n",
    "                    pbar.set_postfix_str(f\"Games: {game_count}/{self.max_games}\")\n",
    "        \n",
    "        # Сохраняем новый CSV\n",
    "        output_df = pd.DataFrame(output_data)\n",
    "        output_csv_path = os.path.join(self.output_dir, \"_info.csv\")\n",
    "        output_df.to_csv(output_csv_path, index=False)\n",
    "        \n",
    "        print(f\"Обработано {game_count} партий\")\n",
    "        for split_name, count in split_counts.items():\n",
    "            print(f\"{split_name}: {count} партий ({count / game_count * 100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07925ade-6beb-464c-bd36-deed8af3b78c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T22:18:20.274735Z",
     "iopub.status.busy": "2025-05-04T22:18:20.271616Z",
     "iopub.status.idle": "2025-05-04T22:42:33.529479Z",
     "shell.execute_reply": "2025-05-04T22:42:33.528197Z",
     "shell.execute_reply.started": "2025-05-04T22:18:20.274602Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing games: 25006it [24:11, 17.23it/s, Games: 25000/25000]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработано 25000 партий\n",
      "train: 17384 партий (69.5%)\n",
      "val: 3790 партий (15.2%)\n",
      "test: 3826 партий (15.3%)\n"
     ]
    }
   ],
   "source": [
    "encoder = MatrixEncoder()\n",
    "converter = MovesToNpyConverter(\n",
    "    csv_path=\"/home/jupyter/datasphere/project/full_labeled.csv\",\n",
    "    encoder=encoder,\n",
    "    output_dir=\"/home/jupyter/datasphere/project/transformer_dataset\",\n",
    "    max_games=25_000\n",
    ")\n",
    "converter.process_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa097312-4a7a-4641-ae93-8a37af23e284",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T22:15:16.552419Z",
     "iopub.status.busy": "2025-05-04T22:15:16.549218Z",
     "iopub.status.idle": "2025-05-04T22:15:16.598358Z",
     "shell.execute_reply": "2025-05-04T22:15:16.595923Z",
     "shell.execute_reply.started": "2025-05-04T22:15:16.552297Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import json\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class Board2Vec(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        # Входной блок с 12 каналов (6 фигур × 2 цвета + информация про рокировку, взятие на проходе и promotion)\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(12, hidden_dim, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(hidden_dim),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Резидуальные блоки\n",
    "        self.block1 = ResidualBlock(hidden_dim)\n",
    "        self.block2 = ResidualBlock(hidden_dim)\n",
    "        self.block3 = ResidualBlock(hidden_dim)\n",
    "\n",
    "        # Глобальный пуллинг и финальные слои\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, boards: torch.Tensor):\n",
    "        # boards: (batch_size, 12, 8, 8)\n",
    "        x = self.initial(boards)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # Конкатенация с дополнительными признаками\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37028d5a-1954-4296-a3ed-108361e6b518",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-04T22:15:21.354357Z",
     "iopub.status.busy": "2025-05-04T22:15:21.351128Z",
     "iopub.status.idle": "2025-05-04T22:15:21.851887Z",
     "shell.execute_reply": "2025-05-04T22:15:21.849570Z",
     "shell.execute_reply.started": "2025-05-04T22:15:21.354217Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([1, 12, 8, 8])\n",
      "Output tensor shape: torch.Size([1, 64])\n",
      "Output: tensor([[ 1.1006, -0.4905, -0.1791,  0.5547,  0.1832,  0.7637, -1.1510,  0.2183,\n",
      "          0.2191, -0.8844,  0.1198, -0.1497, -0.8179, -0.6183, -0.4953, -0.1349,\n",
      "         -0.0947,  0.2664, -0.2242,  0.2766,  0.1191,  0.3455,  0.2219, -0.4242,\n",
      "         -0.1339,  0.1539, -0.8319, -0.3708,  0.4171,  0.8627, -0.4695, -0.1314,\n",
      "         -0.4423,  0.4281,  0.2627, -0.7244, -0.7913,  0.4238,  0.5830, -0.7772,\n",
      "          0.0208,  0.0298,  0.0623,  1.0745,  0.5161,  0.3190,  1.0676, -1.0908,\n",
      "          0.7710,  0.1538, -0.6977, -0.3819,  0.6135, -0.9161, -1.0715, -0.0804,\n",
      "          0.7776,  0.3000, -0.3934,  0.2394, -0.3361,  0.8925, -0.4659, -0.3089]])\n"
     ]
    }
   ],
   "source": [
    "# Загрузка конфигурации модели\n",
    "checkpoint_dir = \"checkpoints\"\n",
    "with open(os.path.join(checkpoint_dir, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Создание модели с параметрами из конфига\n",
    "model = Board2Vec(\n",
    "    hidden_dim=config[\"HIDDEN_DIM\"],\n",
    "    output_dim=config[\"OUTPUT_DIM\"]\n",
    ")\n",
    "\n",
    "# Загрузка весов модели из чекпоинта\n",
    "checkpoint_path = os.path.join(checkpoint_dir, \"board2vec_epoch1.pt\")\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device('cpu')))\n",
    "model.eval()  # переводим модель в режим оценки\n",
    "\n",
    "# Создание случайного тензора размера (12, 8, 8)\n",
    "random_tensor = torch.randn(12, 8, 8)  # можно также использовать torch.rand для значений [0, 1)\n",
    "\n",
    "# Добавляем размер батча (1 в данном случае)\n",
    "input_tensor = random_tensor.unsqueeze(0)  # теперь размер (1, 12, 8, 8)\n",
    "\n",
    "# Пропускаем тензор через модель\n",
    "with torch.no_grad():  # отключаем вычисление градиентов\n",
    "    output = model(input_tensor)\n",
    "\n",
    "print(\"Input tensor shape:\", input_tensor.shape)\n",
    "print(\"Output tensor shape:\", output.shape)\n",
    "print(\"Output:\", output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f5cccc-8041-4474-96b3-8029f684ee62",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-04T22:14:49.712976Z",
     "iopub.status.idle": "2025-05-04T22:14:49.713967Z",
     "shell.execute_reply": "2025-05-04T22:14:49.713746Z",
     "shell.execute_reply.started": "2025-05-04T22:14:49.713715Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "class EmbeddingConverter:\n",
    "    def __init__(self, model, input_dir, output_dir, batch_size=32, device='cuda'):\n",
    "        self.model = model.to(device)\n",
    "        self.model.eval()\n",
    "        self.input_dir = input_dir\n",
    "        self.output_dir = output_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        \n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "    def process_directory(self):\n",
    "        # Собираем все .npy файлы рекурсивно\n",
    "        file_list = []\n",
    "        for root, dirs, files in os.walk(self.input_dir):\n",
    "            for filename in files:\n",
    "                if filename.endswith('.npy'):\n",
    "                    full_path = os.path.join(root, filename)\n",
    "                    file_list.append(full_path)\n",
    "\n",
    "        # Обрабатываем файлы\n",
    "        for input_path in tqdm(file_list, desc=\"Processing files\"):\n",
    "            # Получаем относительный путь\n",
    "            rel_path = os.path.relpath(input_path, start=self.input_dir)\n",
    "            output_path = os.path.join(self.output_dir, rel_path)\n",
    "            \n",
    "            # Создаем целевую директорию, если ее нет\n",
    "            os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "            \n",
    "            # Обрабатываем файл\n",
    "            sequence = np.load(input_path)\n",
    "            embeddings = self._process_sequence(sequence)\n",
    "            np.save(output_path, embeddings)\n",
    "    \n",
    "    def _process_sequence(self, sequence):\n",
    "        num_positions = sequence.shape[0]\n",
    "        embeddings = []\n",
    "        \n",
    "        for i in range(0, num_positions, self.batch_size):\n",
    "            batch = sequence[i:i+self.batch_size]\n",
    "            batch_tensor = torch.from_numpy(batch).float().to(self.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_embeddings = self.model(batch_tensor).cpu().numpy()\n",
    "            \n",
    "            embeddings.append(batch_embeddings)\n",
    "        \n",
    "        return np.concatenate(embeddings, axis=0)\n",
    "\n",
    "\n",
    "# Пример использования:\n",
    "if __name__ == \"__main__\":    \n",
    "    # Создаем конвертер и обрабатываем данные\n",
    "    converter = EmbeddingConverter(\n",
    "        model=model,\n",
    "        input_dir=\"/home/jupyter/datasphere/project/transformer_dataset/\",  # директория с исходными .npy файлами\n",
    "        output_dir=\"/home/jupyter/datasphere/project/transformer_dataset_2/\",  # директория для сохранения эмбеддингов\n",
    "        batch_size=64,  # можно настроить в зависимости от доступной памяти\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    )\n",
    "    \n",
    "    converter.process_directory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6c6939-bcd9-4098-800e-23a7b2b325fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
